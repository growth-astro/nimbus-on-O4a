{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook shows how to create optional files for an event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating fields.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_20230627 = pd.read_csv('event_20230627/2023-06-27_v5.csv', sep=',') # Load the event data file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using information on gracedb, set up the $t_{start}$ and $t_{end}$ for the analysis. Use $t_0$ or coalescence time as $t_{start}$ set $t_{end}$ to be three days after $t_{start}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = '2023-06-27T01:53:37.819'\n",
    "t_end = '2023-06-30T01:53:37.819'\n",
    "\n",
    "# Convert t_start and t_end to Time in isot format\n",
    "t_start = Time(t_start,format='isot')\n",
    "t_end = Time(t_end,format='isot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are only concerned with observations between $t_{start}$ and $t_{end}$, create a data_event file using the start and end time in jd format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_event = data_20230627[(data_20230627['jd']>=t_start.jd)&(data_20230627['jd']<=t_end.jd)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all the unique fields in the observation file with status $1$. nimbus only takes those observations into account that have a status of $1$. status $1$ indicates a complete observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = np.unique(data_event[data_event['status']==1]['field'])\n",
    "fields = fields.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the fields in a file. This will be useful while running the jobs as the jobs can be queued for all the fields in an event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('fields.txt', 'w+')\n",
    "for field in fields:\n",
    "    content = str(field)\n",
    "    file.write(content)\n",
    "    file.write('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part of this notebook deals with files that can be generated once the likelihood files are obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'event_20230518/likelihood/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some likelihood files can be from fields with $E(B-V) >2$ and nimbus returns an error in that case in the .err files. To keep a note of those fields, create a status.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there is a lot of file reading to do:\n",
    "def read_text_file(file_path): \n",
    "    with open(file_path, 'r') as f: \n",
    "        content = f.read()\n",
    "    return content\n",
    "\n",
    "# Read a file that has too much extinction (added in the repository)\n",
    "extinction = read_text_file('/home/vaidehi.gupta/nimbus_analysis/O4_nimbus/event_20230521/err/multi_field_1636.err')\n",
    "\n",
    "# Store the name of any .err file which has the same content.\n",
    "extinction_files = []\n",
    "for file in os.listdir(directory):\n",
    "    file_path = f\"{directory}{file}\"\n",
    "    content = read_text_file(file_path)\n",
    "    if content == extinction:\n",
    "        extinction_files.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For field number $880$ and $881$, the ZTF_fields.pkl file, doesn't have any information. If these fields appear in the observation file, store that in the status file as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('status.txt', 'w+') as f:\n",
    "    for fld in fields:\n",
    "        if fld == 880 or fld == 881:\n",
    "            content = f\"{fld}: No extinction information found\"\n",
    "            f.write(content)\n",
    "            f.write('\\n')\n",
    "    for file in extinction_files:\n",
    "        field = [int(s) for s in re.findall(r'\\d+', file)]\n",
    "        for fld in field:\n",
    "            content = f\"{fld}: extinction\"\n",
    "            f.write(content)\n",
    "            f.write('\\n')     \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-check if you have been successfully able to generate all the meaningful likelihood files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/home/vaidehi.gupta/nimbus_analysis/O4_nimbus/event_20230627/likelihood/'\n",
    "fields_done = []\n",
    "for file in os.listdir(directory):\n",
    "    fields_done.append([int(s) for s in re.findall(r'\\d+', file)][0])\n",
    "\n",
    "print(len(fields), len(fields_done))\n",
    "\n",
    "for f in fields:\n",
    "    if f not in fields_done:\n",
    "        print(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gwtm_api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
